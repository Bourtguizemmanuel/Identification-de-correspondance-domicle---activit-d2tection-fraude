{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "943bac2c-ee3c-49ad-8418-2c66eb41a323",
   "metadata": {},
   "source": [
    "# <font color=#0c2290> Projet d√©tection de fraudes au chronotackygraphe üìä"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e24bf8-c9af-4743-b492-0e8052cd1274",
   "metadata": {},
   "source": [
    "def generer_rapport(df_suspects, fichier_sortie='rapport_fraudes.csv'):\n",
    "    \"\"\"\n",
    "    G√©n√®re un rapport des cas suspects\n",
    "    \"\"\"\n",
    "    if len(df_suspects) == 0:\n",
    "        print(\"\\n‚úì Aucune fraude potentielle d√©tect√©e\")\n",
    "        return\n",
    "    \n",
    "    # Colonnes √† inclure dans le rapport\n",
    "    colonnes_rapport = [\n",
    "        'nom',\n",
    "        'adresse',\n",
    "        'activite',\n",
    "        'distance_domicile_km',\n",
    "        'score_risque',\n",
    "        'latitude_domicile',\n",
    "        'longitude_domicile',\n",
    "        'latitude_position',\n",
    "        'longitude_position'\n",
    "    ]\n",
    "    \n",
    "    # Filtrer les colonnes existantes\n",
    "    colonnes_disponibles = [col for col in colonnes_rapport if col in df_suspects.columns]\n",
    "    df_rapport = df_suspects[colonnes_disponibles].copy()\n",
    "    \n",
    "    # Arrondir les valeurs num√©riques\n",
    "    df_rapport['distance_domicile_km'] = df_rapport['distance_domicile_km'].round(2)\n",
    "    df_rapport['score_risque'] = df_rapport['score_risque'].round(1)\n",
    "    \n",
    "    # Sauvegarder le rapport\n",
    "    df_rapport.to_csv(fichier_sortie, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"\\n {len(df_suspects)} cas suspects d√©tect√©s!\")\n",
    "    print(f\"\\nTop 5 des cas les plus suspects:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for idx, row in df_rapport.head(5).iterrows():\n",
    "        print(f\"\\nChauffeur: {row['nom']}\")\n",
    "        print(f\"  Distance du domicile: {row['distance_domicile_km']:.2f} km\")\n",
    "        print(f\"  Score de risque: {row['score_risque']:.1f}/100\")\n",
    "        print(f\"  Activit√©: {row.get('activite', 'N/A')}\")\n",
    "    \n",
    "    print(f\"\\n‚úì Rapport complet sauvegard√© dans: {fichier_sortie}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Fonction principale\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"D√âTECTION DE FRAUDES POTENTIELLES - CHAUFFEURS\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # Configuration\n",
    "    fichier_domiciles = 'chauffeurs_domiciles.csv'\n",
    "    fichier_positions = 'chauffeurs_positions.csv'\n",
    "    seuil_distance = 5  # km\n",
    "    \n",
    "    print(f\"Param√®tres:\")\n",
    "    print(f\"  - Seuil de distance: {seuil_distance} km\")\n",
    "    print()\n",
    "    \n",
    "    # Charger les donn√©es\n",
    "    df_domiciles = charger_donnees_domiciles(fichier_domiciles)\n",
    "    df_positions = charger_donnees_positions(fichier_positions)\n",
    "    \n",
    "    if df_domiciles is None or df_positions is None:\n",
    "        print(\"\\n Impossible de charger les donn√©es\")\n",
    "        return\n",
    "    \n",
    "    # D√©tecter les fraudes\n",
    "    print(\"\\nAnalyse en cours...\")\n",
    "    df_suspects = detecter_fraudes(df_domiciles, df_positions, seuil_distance)\n",
    "    \n",
    "    # G√©n√©rer le rapport\n",
    "    generer_rapport(df_suspects)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Analyse termin√©e\")\n",
    "    print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fc74b6-0beb-41e5-bc8a-4bac02508f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "504af806-ca62-4b40-b1ee-daa0c308a6d8",
   "metadata": {},
   "source": [
    "## **Importer les biblioth√®ques**\n",
    "\n",
    "import pandas as pd\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "from datetime import datetime\n",
    "\n",
    "### **Calcul des kilom√®tres entre deux points (Latitude / Longitude)**\n",
    "\n",
    "def calculer_distance_haversine(lat1: float, lon1: float, lat2: float, lon2: float) -> float:\n",
    "    \"\"\"\n",
    "    Calcule la distance en kilom√®tres entre deux points\n",
    "    g√©ographiques en utilisant la formule de Haversine.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lat1 : float -> Latitude du point de d√©part (en degr√©s).\n",
    "    lon1 : float -> Longitude du point de d√©part (en degr√©s).\n",
    "    lat2 : float -> Latitude du point d'arriv√©e (en degr√©s).\n",
    "    lon2 : float -> Longitude du point d'arriv√©e (en degr√©s).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float -> Distance en kilom√®tres entre les deux points.\n",
    "    \"\"\"\n",
    "\n",
    "    # Conversion des degr√©s en radians\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Calcul des diff√©rences\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    # Application de la formule de Haversine\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "\n",
    "    # Rayon de la Terre en kilom√®tres\n",
    "    r = 6371\n",
    "\n",
    "    return c * r\n",
    "\n",
    "### Exemple d'utilisation\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Paris -> Lyon\n",
    "    distance = calculer_distance_haversine(48.8566, 2.3522, 45.7640, 4.8357)\n",
    "    print(f\"Distance Paris -> Lyon : {distance:.2f} km\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7fe245-6391-4568-ae5a-4e6a85904a01",
   "metadata": {},
   "source": [
    "## **Chargement du fichier des positions des domiciles des chauffeurs**\n",
    "## ===============================================================\n",
    "\n",
    "### **Chemin vers le fichier CSV**\n",
    "df = pd.read_csv(\n",
    "    \"Users\", \"bourtguize\", \"Desktop\", \"dataSuits\",\n",
    "    \"FORMATION DATA ANALYST - Septembre 2025\",\n",
    "    \"DOSSIER MODULE 6 - Projet final & Pr√©pa pro\",\n",
    "    \"Data-projet\", \"data\", \"personnel_coordonnees.csv\"\n",
    ")\n",
    "\n",
    "### **Liste des encodages √† tester**\n",
    "ENCODAGES = [\"utf-8\", \"latin-1\", \"cp1252\", \"iso-8859-1\"]\n",
    "\n",
    "### **Colonnes requises apr√®s renommage**\n",
    "COLONNES_REQUISES = [\"nom\", \"latitude_domicile\", \"longitude_domicile\"]\n",
    "\n",
    "#### **=============================================================**\n",
    "#### Format attendu : nom, latitude_domicile, longitude_domicile\n",
    "#### **=============================================================**\n",
    "\n",
    "### **Correspondance des colonnes brutes -> nom attendu**\n",
    "COLONNES_RENOMMAGE = {\n",
    "    \"Nom\":       \"nom\",\n",
    "    \"latitude\":  \"latitude_domicile\",\n",
    "    \"longitude\": \"longitude_domicile\",\n",
    "}\n",
    "\n",
    "\n",
    "def load_domiciles_file(file_path: str = FILE_PATH) -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Charge le fichier CSV des domiciles des chauffeurs.\n",
    "\n",
    "    Tente plusieurs encodages successivement jusqu'√† un\n",
    "    chargement r√©ussi. V√©rifie ensuite la pr√©sence des\n",
    "    colonnes obligatoires apr√®s renommage.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str -> Chemin vers le fichier CSV.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame | None\n",
    "        DataFrame nettoy√© si le fichier est valide,\n",
    "        None sinon.\n",
    "    \"\"\"\n",
    "\n",
    "    for encoding in ENCODAGES:\n",
    "        try:\n",
    "            # --- Lecture du fichier CSV ---\n",
    "            df = pd.read_csv(file_path, encoding=encoding, sep=\";\")\n",
    "\n",
    "            # --- Renommage des colonnes ---\n",
    "            df = df.rename(columns=COLONNES_RENOMMAGE)\n",
    "\n",
    "            # --- V√©rification des colonnes requises ---\n",
    "            colonnes_manquantes = [\n",
    "                col for col in COLONNES_REQUISES if col not in df.columns\n",
    "            ]\n",
    "\n",
    "            if colonnes_manquantes:\n",
    "                print(f\"‚úó Colonnes manquantes : {colonnes_manquantes}\")\n",
    "                print(f\"  Colonnes pr√©sentes  : {list(df.columns)}\")\n",
    "                return None\n",
    "\n",
    "            # --- Retour du DataFrame valid√© ---\n",
    "            print(f\"‚úì {len(df)} chauffeurs charg√©s (encodage : {encoding})\")\n",
    "            return df\n",
    "\n",
    "        except (UnicodeDecodeError, UnicodeError):\n",
    "            # Encodage incompatible -> on teste le suivant\n",
    "            continue\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó Erreur avec l'encodage '{encoding}' : {e}\")\n",
    "            continue\n",
    "\n",
    "    # Aucun encodage ne a fonctionn√©\n",
    "    print(\"‚úó Aucun encodage compatible trouv√© pour le fichier.\")\n",
    "    return None\n",
    "\n",
    "#### Test : uniquement si ouvre fichier directement\n",
    "### =============================================================\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Chargement du fichier domiciles\n",
    "    df_domiciles = load_domiciles_file()\n",
    "\n",
    "    if df_domiciles is not None:\n",
    "        print(\"\\n--- Aper√ßu des donn√©es ---\")\n",
    "        print(df_domiciles.head())\n",
    "    else:\n",
    "        print(\"\\n‚úó √âchec du chargement du fichier.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70954943-6864-4418-b2b6-b66eecd0f599",
   "metadata": {},
   "source": [
    "### **def charger_donnees_positions(fichier_positions):**\n",
    "## ======================================================\n",
    "\n",
    "    encodages = ['utf-8', 'latin1', 'iso-8859-1', 'cp1252', 'utf-16']\n",
    "    \n",
    "    for encoding in encodages:\n",
    "        try:\n",
    "            # Ajouter sep=';' pour le s√©parateur point-virgule\n",
    "            df = pd.read_csv(\"/Users/bourtguize/Desktop/dataSuits/FORMATION DATA ANALYST - Septembre 2025/DOSSIER MODULE 6 - Projet final & PreÃÅpa pro/Data-projet/temps de service_juin.csv\", encoding=encoding, sep=';')\n",
    "            \n",
    "            # Renommer les colonnes pour correspondre aux noms attendus\n",
    "            df = df.rename(columns={\n",
    "                'Chauffeur': 'nom',\n",
    "                'Latitude': 'latitude_position',\n",
    "                'Longitude': 'longitude_position',\n",
    "                'Code de travail': 'activite'\n",
    "            })\n",
    "            \n",
    "            # V√©rifier les colonnes requises\n",
    "            colonnes_requises = ['nom', 'latitude_position', 'longitude_position', 'activite']\n",
    "            colonnes_manquantes = [col for col in colonnes_requises if col not in df.columns]\n",
    "            \n",
    "            if colonnes_manquantes:\n",
    "                print(f\"Colonnes manquantes dans le fichier positions: {colonnes_manquantes}\")\n",
    "                print(f\"Colonnes pr√©sentes: {list(df.columns)}\")\n",
    "                return None\n",
    "            \n",
    "            print(f\"‚úì {len(df)} positions charg√©es depuis le fichier positions (encodage: {encoding})\")\n",
    "            print(f\"  Colonnes: {list(df.columns)}\")\n",
    "            return df\n",
    "            \n",
    "        except (UnicodeDecodeError, UnicodeError):\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur avec encodage {encoding}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"Impossible de lire le fichier avec les encodages test√©s: {encodages}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "d86f063e-62fd-4e25-9d70-abd44f8f796f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes: ['Date et heure de d√©but', 'Date et heure de fin', 'Longitude', 'Latitude', 'Position', 'V√©hicule', 'Chauffeur', 'Code de travail', 'Description', 'Dur√©e']\n",
      "\n",
      "  Date et heure de d√©but Date et heure de fin  Longitude  Latitude  \\\n",
      "0    2024-06-07 07:01:00  2024-06-07 07:03:00     4.0002   43.6516   \n",
      "1    2024-06-07 07:03:00  2024-06-07 07:07:00     4.0002   43.6516   \n",
      "2    2024-06-07 07:07:00  2024-06-07 07:28:00     3.9994   43.6587   \n",
      "3    2024-06-07 07:28:00  2024-06-07 07:40:00     3.9992   43.6587   \n",
      "4    2024-06-07 07:40:00  2024-06-07 08:47:00     3.9359   43.5935   \n",
      "\n",
      "                                            Position           V√©hicule  \\\n",
      "0  FRA - Rue Jules Milhau (1-) - 34670 - Baillarg...  K1619 (FR-898-VC)   \n",
      "1  FRA - Rue Jules Milhau (1-) - 34670 - Baillarg...  K1619 (FR-898-VC)   \n",
      "2  FRA - Avenue de la Biste (350-) - 34670 - Bail...  K1619 (FR-898-VC)   \n",
      "3  FRA - Avenue de la Biste (350-) - 34670 - Bail...  K1619 (FR-898-VC)   \n",
      "4  FRA - Route de Vaugui√®res (-) - 34970 - Lattes...  K1619 (FR-898-VC)   \n",
      "\n",
      "      Chauffeur Code de travail Description     Dur√©e  \n",
      "0  Anthony ODIN              AA     Travail  00:02:00  \n",
      "1  Anthony ODIN              RD    Conduite  00:04:00  \n",
      "2  Anthony ODIN              AA     Travail  00:21:00  \n",
      "3  Anthony ODIN              RD    Conduite  00:12:00  \n",
      "4  Anthony ODIN              AA     Travail  01:07:00  \n"
     ]
    }
   ],
   "source": [
    "df_test2 = pd.read_excel(\"/Users/bourtguize/Desktop/dataSuits/FORMATION DATA ANALYST - Septembre 2025/DOSSIER MODULE 6 - Projet final & Pr√©pa pro/Data-projet/temps de service_juin.xlsx\")\n",
    "print(\"Colonnes:\", df_test2.columns.tolist())\n",
    "print()\n",
    "print(df_test2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "dbac6cbc-c5cb-4bba-b953-1c6210fe1c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Colonnes renomm√©es\n"
     ]
    }
   ],
   "source": [
    "# √Ä ex√©cuter AVANT d'appeler detecter_fraudes\n",
    "df_positions = df_positions.rename(columns={\n",
    "    'Chauffeur': 'nom',\n",
    "    'Latitude': 'latitude_position',\n",
    "    'Longitude': 'longitude_position',\n",
    "    'Code de travail': 'activite'\n",
    "})\n",
    "print(\"‚úì Colonnes renomm√©es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "3afcf07f-d54b-43a1-86f9-9b040ff78e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "fichier_domiciles = '/Users/bourtguize/Desktop/dataSuits/FORMATION DATA ANALYST - Septembre 2025/DOSSIER MODULE 6 - Projet final & Pr√©pa pro/Data-projet/data/liste_personnel_avec_coordonnees_1.csv'\n",
    "\n",
    "fichier_positions = '/Users/bourtguize/Desktop/dataSuits/FORMATION DATA ANALYST - Septembre 2025/DOSSIER MODULE 6 - Projet final & Pr√©pa pro/Data-projet/temps de service_juin.csv'\n",
    "\n",
    "seuil_distance = 0.5  # km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "9472d22c-6997-40ee-81f2-a7aa166a4fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df_merged, seuil_distance_km= 0.5):\n",
    "    # Fix the first line that had a syntax error\n",
    "    df_merged['Date et heure de d√©but'] = pd.to_datetime(df_merged['Date et heure de d√©but'])\n",
    "    df_merged['Date et heure de fin'] = pd.to_datetime(df_merged['Date et heure de fin'])\n",
    "    df_merged['Jour'] = df_merged['Date et heure de d√©but'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Convertir datetime.time en minutes\n",
    "    def time_to_minutes(time_obj):\n",
    "        if pd.isna(time_obj):\n",
    "            return 0\n",
    "        try:\n",
    "            # Si c'est un objet time\n",
    "            if hasattr(time_obj, 'hour'):\n",
    "                return time_obj.hour * 60 + time_obj.minute + time_obj.second / 60\n",
    "            # Si c'est une cha√Æne\n",
    "            else:\n",
    "                parts = str(time_obj).split(':')\n",
    "                return int(parts[0]) * 60 + int(parts[1]) + (int(parts[2]) if len(parts) > 2 else 0) / 60\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    df_merged['Dur√©e_minutes'] = df_merged['Dur√©e'].apply(time_to_minutes)\n",
    "    \n",
    "    # Filtrer uniquement les chauffeurs \"en travail\"\n",
    "    df_travail = df_merged[df_merged['Description'].str.lower().str.contains('travail', na=False)]\n",
    "    \n",
    "    if len(df_travail) == 0:\n",
    "        print(\"Aucun chauffeur en activit√© de travail trouv√©\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Calculer la distance pour chaque position\n",
    "    df_travail = df_travail.copy()\n",
    "    df_travail['distance_domicile_km'] = df_travail.apply(\n",
    "        lambda row: calculer_distance_haversine(\n",
    "            row['latitude_domicile'],\n",
    "            row['longitude_domicile'],\n",
    "            row['latitude_position'],\n",
    "            row['longitude_position']\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Identifier les cas suspects (distance < seuil)\n",
    "    df_suspects = df_travail[df_travail['distance_domicile_km'] < seuil_distance_km].copy()\n",
    "    \n",
    "    # Calculer un score de risque (plus proche = plus suspect)\n",
    "    df_suspects['score_risque'] = (1 - (df_suspects['distance_domicile_km'] / seuil_distance_km)) * 100\n",
    "    \n",
    "    # Trier par score de risque d√©croissant\n",
    "    df_suspects = df_suspects.sort_values('score_risque', ascending=False)\n",
    "    \n",
    "    return df_suspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "071b0cf2-65af-4cf1-928a-0871b08eec2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.time'>\n",
      "0    00:14:00\n",
      "1    00:25:00\n",
      "2    00:17:00\n",
      "3    00:01:00\n",
      "4    00:05:00\n",
      "Name: Dur√©e, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(type(df_positions['Dur√©e'].iloc[0]))\n",
    "print(df_positions['Dur√©e'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "382317da-c6ab-484d-a62e-cfeceec6cc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== D√âTECTION DES FRAUDES ===\n",
      "Colonnes dans df_merged apr√®s fusion:\n",
      "['Date et heure de d√©but', 'Position', 'latitude_position', 'longitude_position', 'Date et heure de fin', 'V√©hicule', 'nom', 'activite', 'Description', 'Dur√©e', 'Pr√©nom', \"Date d'embauche\", 'Date de naissance', 'Carte N¬∞', 'Adresse 1', 'code_postal', 'commune', 'latitude_domicile', 'longitude_domicile']\n",
      "\n",
      "Aucun chauffeur en activit√© de travail trouv√©\n",
      "\n",
      "Aucune fraude d√©tect√©e\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== D√âTECTION DES FRAUDES ===\")\n",
    "df_suspects = detecter_fraudes(df_domiciles, df_positions, seuil_distance)\n",
    "\n",
    "if df_suspects is not None and len(df_suspects) > 0:\n",
    "    print(f\"\\n {len(df_suspects)} cas suspects d√©tect√©s !\")\n",
    "    print(\"\\nAper√ßu des cas suspects :\")\n",
    "    print(df_suspects[['nom', 'distance_domicile_km', 'score_risque']].head(10))\n",
    "    \n",
    "    # Saugegarder\n",
    "    chemin_sortie = '/Users/bourtguize/Desktop/fraudes_detectees.csv'\n",
    "    df_suspects.to_csv(chemin_sortie, index=False, sep=';', encoding='utf-8')\n",
    "    print(f\"\\n‚úì Fichier sauvegard√© sur le Bureau : fraudes_detectees.csv\")\n",
    "else:\n",
    "    print(\"\\nAucune fraude d√©tect√©e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "82464a3c-8483-45a7-a220-fb502cf163b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"D√âTECTION DE FRAUDES POTENTIELLES - CHAUFFEURS\")\n",
    "    print(\"=\" * 80)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "e93b75df-5cc4-48fa-a913-8a944d1ed8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param√®tres:\n",
      "  - Seuil de distance: (0, 5) km\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "fichier_domiciles = '/Users/bourtguize/Desktop/dataSuits/FORMATION DATA ANALYST - Septembre 2025/DOSSIER MODULE 6 - Projet final & Pr√©pa pro/Data-projet/data/liste_personnel_avec_coordonnees_1.csv'\n",
    "\n",
    "fichier_positions = '/Users/bourtguize/Desktop/dataSuits/FORMATION DATA ANALYST - Septembre 2025/DOSSIER MODULE 6 - Projet final & Pr√©pa pro/Data-projet/temps de service_juin.csv'\n",
    "\n",
    "seuil_distance = 0,5 # km\n",
    "\n",
    "print(f\"Param√®tres:\")\n",
    "print(f\"  - Seuil de distance: {seuil_distance} km\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0632a0ff-2625-42ea-90ef-6863332a9862",
   "metadata": {},
   "source": [
    "## **D√©tecter les fraudes**\n",
    "## ==============================\n",
    "print(\"\\nAnalyse en cours...\")\n",
    "\n",
    "# Renommer les colonnes si n√©cessaire\n",
    "if 'Chauffeur' in df_positions.columns and 'nom' not in df_positions.columns:\n",
    "    # Check if 'Code de travail' exists before renaming\n",
    "    rename_dict = {\n",
    "        'Chauffeur': 'nom',\n",
    "        'Latitude': 'latitude_position',\n",
    "        'Longitude': 'longitude_position'\n",
    "    }\n",
    "    \n",
    "    # Only add 'Code de travail' to rename dict if it exists\n",
    "    if 'Code de travail' in df_positions.columns:\n",
    "        rename_dict['Code de travail'] = 'activite'\n",
    "    \n",
    "    df_positions = df_positions.rename(columns=rename_dict)\n",
    "    print(\"‚úì Colonnes de df_positions renomm√©es\")\n",
    "\n",
    "# Supprimer les colonnes en double\n",
    "df_positions = df_positions.loc[:, ~df_positions.columns.duplicated()]\n",
    "\n",
    "print(\"‚úì Colonnes en double supprim√©es\")\n",
    "print(\"Colonnes finales:\", df_positions.columns.tolist())\n",
    "\n",
    "# Check if df_domiciles and df_positions are not None before proceeding\n",
    "if df_domiciles is None:\n",
    "    print(\"Erreur: df_domiciles est None. Veuillez v√©rifier les √©tapes pr√©c√©dentes.\")\n",
    "    # Initialize with empty DataFrame if needed\n",
    "    # df_domiciles = pd.DataFrame()\n",
    "elif df_positions is None:\n",
    "    print(\"Erreur: df_positions est None. Veuillez v√©rifier les √©tapes pr√©c√©dentes.\")\n",
    "    # Initialize with empty DataFrame if needed\n",
    "    # df_positions = pd.DataFrame()\n",
    "else:\n",
    "    print(\"\\nAnalyse en cours...\")\n",
    "    # Make sure the detecter_fraudes function doesn't require 'activite' column\n",
    "    # or handle its absence properly\n",
    "    df_suspects = detecter_fraudes(df_domiciles, df_positions, seuil_distance)\n",
    "    \n",
    "    # Check if df_suspects is not None before generating report\n",
    "    if df_suspects is not None:\n",
    "        # G√©n√©rer le rapport\n",
    "        generer_rapport(df_suspects)\n",
    "    else:\n",
    "        print(\"Erreur: La d√©tection de fraudes n'a pas retourn√© de r√©sultats valides.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "e627ee4b-7bad-4038-acfe-5e933db7d9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chargement r√©ussi avec sep=';'\n",
      "Lignes : 105\n",
      "Colonnes : ['Nom', 'Pr√©nom', \"Date d'embauche\", 'Date de naissance', 'Carte N¬∞', 'Adresse 1', 'code_postal', 'commune', 'latitude', 'longitude']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fichier_csv = '/Users/bourtguize/Desktop/dataSuits/FORMATION DATA ANALYST - Septembre 2025/DOSSIER MODULE 6 - Projet final & Pr√©pa pro/Data-projet/data/liste_personnel_avec_coordonnees_1.csv'\n",
    "\n",
    "# Essayer de charger avec diff√©rents s√©parateurs\n",
    "try:\n",
    "    # Essai 1 : avec point-virgule\n",
    "    df_test = pd.read_csv(fichier_csv, sep=';', encoding='utf-8')\n",
    "    print(\"‚úì Chargement r√©ussi avec sep=';'\")\n",
    "    print(f\"Lignes : {len(df_test)}\")\n",
    "    print(f\"Colonnes : {df_test.columns.tolist()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur avec sep=';' : {e}\")\n",
    "    \n",
    "    try:\n",
    "        # Essai 2 : avec virgule\n",
    "        df_test = pd.read_csv(fichier_csv, sep=',', encoding='utf-8')\n",
    "        print(\"‚úì Chargement r√©ussi avec sep=','\")\n",
    "        print(f\"Lignes : {len(df_test)}\")\n",
    "        print(f\"Colonnes : {df_test.columns.tolist()}\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Erreur avec sep=',' : {e2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "b51765b2-76a5-4934-9084-ec0c42257bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== V√âRIFICATION DES DONN√âES ===\n",
      "df_domiciles existe : True\n",
      "df_positions existe : True\n",
      "‚úì df_domiciles : 105 lignes\n",
      "  Colonnes : ['nom', 'Pr√©nom', \"Date d'embauche\", 'Date de naissance', 'Carte N¬∞', 'Adresse 1', 'code_postal', 'commune', 'latitude_domicile', 'longitude_domicile']\n",
      "‚úì df_positions : 37411 lignes\n",
      "  Colonnes : ['Date et heure de d√©but', 'Position', 'latitude_position', 'longitude_position', 'Date et heure de fin', 'V√©hicule', 'nom', 'activite', 'Description', 'Dur√©e']\n"
     ]
    }
   ],
   "source": [
    "print(\"=== V√âRIFICATION DES DONN√âES ===\")\n",
    "print(f\"df_domiciles existe : {'df_domiciles' in locals()}\")\n",
    "print(f\"df_positions existe : {'df_positions' in locals()}\")\n",
    "\n",
    "if 'df_domiciles' in locals() and df_domiciles is not None:\n",
    "    print(f\"‚úì df_domiciles : {len(df_domiciles)} lignes\")\n",
    "    print(f\"  Colonnes : {df_domiciles.columns.tolist()}\")\n",
    "else:\n",
    "    print(\"‚úó df_domiciles n'est pas charg√© correctement\")\n",
    "\n",
    "if 'df_positions' in locals() and df_positions is not None:\n",
    "    print(f\"‚úì df_positions : {len(df_positions)} lignes\")\n",
    "    print(f\"  Colonnes : {df_positions.columns.tolist()}\")\n",
    "else:\n",
    "    print(\"‚úó df_positions n'est pas charg√© correctement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "4b02318e-3519-4541-9bde-67b16005828c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RECHARGEMENT DE df_domiciles ===\n",
      "Colonnes manquantes dans le fichier domiciles: ['latitude_domicile', 'longitude_domicile']\n",
      "Colonnes pr√©sentes: ['D√©but Edition', 'Fin Edition', 'nom', 'Pr√©nom', 'V√©hicule', 'Kilom√®tres', 'Amplitude', 'Effectif', 'R√©mun√©r√©', 'Jours travaill√©s', \"Jours d'absence\", 'Travail', 'Conduite', 'Repos']\n",
      "ERREUR : df_domiciles n'a pas pu √™tre charg√©\n",
      "\n",
      "Essayons de charger manuellement...\n",
      "‚úì Chargement manuel r√©ussi : 105 lignes\n",
      "  Colonnes : ['nom', 'Pr√©nom', \"Date d'embauche\", 'Date de naissance', 'Carte N¬∞', 'Adresse 1', 'code_postal', 'commune', 'latitude_domicile', 'longitude_domicile']\n"
     ]
    }
   ],
   "source": [
    "# Recharger df_domiciles\n",
    "print(\"=== RECHARGEMENT DE df_domiciles ===\")\n",
    "df_domiciles = charger_donnees_domiciles(fichier_domiciles)\n",
    "\n",
    "if df_domiciles is not None:\n",
    "    print(f\"‚úì df_domiciles charg√© : {len(df_domiciles)} lignes\")\n",
    "    print(f\"  Colonnes : {df_domiciles.columns.tolist()}\")\n",
    "    \n",
    "    # V√©rifier les colonnes n√©cessaires\n",
    "    print(\"\\n=== V√âRIFICATION DES COLONNES ===\")\n",
    "    print(f\"'nom' pr√©sent : {'nom' in df_domiciles.columns}\")\n",
    "    print(f\"'latitude_domicile' pr√©sent : {'latitude_domicile' in df_domiciles.columns}\")\n",
    "    print(f\"'longitude_domicile' pr√©sent : {'longitude_domicile' in df_domiciles.columns}\")\n",
    "else:\n",
    "    print(\"ERREUR : df_domiciles n'a pas pu √™tre charg√©\")\n",
    "    print(\"\\nEssayons de charger manuellement...\")\n",
    "    \n",
    "    # Chargement manuel\n",
    "    df_domiciles = pd.read_csv(fichier_domiciles, sep=';', encoding='utf-8')\n",
    "    df_domiciles = df_domiciles.rename(columns={\n",
    "        'Nom': 'nom',\n",
    "        'latitude': 'latitude_domicile',\n",
    "        'longitude': 'longitude_domicile'\n",
    "    })\n",
    "    print(f\"‚úì Chargement manuel r√©ussi : {len(df_domiciles)} lignes\")\n",
    "    print(f\"  Colonnes : {df_domiciles.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "463a45cf-5d29-4b8d-9247-7413f51574fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== D√âTECTION DES FRAUDES ===\n",
      "Colonnes dans df_merged apr√®s fusion:\n",
      "['Date et heure de d√©but', 'Position', 'latitude_position', 'longitude_position', 'Date et heure de fin', 'V√©hicule', 'nom', 'activite', 'Description', 'Dur√©e', 'Pr√©nom', \"Date d'embauche\", 'Date de naissance', 'Carte N¬∞', 'Adresse 1', 'code_postal', 'commune', 'latitude_domicile', 'longitude_domicile']\n",
      "\n",
      "Aucun chauffeur en activit√© de travail trouv√©\n",
      "\n",
      "Aucune fraude d√©tect√©e avec les crit√®res actuels\n",
      "Seuil de distance utilis√© : (0, 5) km\n"
     ]
    }
   ],
   "source": [
    "# Lancer la d√©tection\n",
    "print(\"\\n=== D√âTECTION DES FRAUDES ===\")\n",
    "df_suspects = detecter_fraudes(df_domiciles, df_positions, seuil_distance)\n",
    "\n",
    "if df_suspects is not None and len(df_suspects) > 0:\n",
    "    print(f\"\\n‚úì {len(df_suspects)} cas suspects d√©tect√©s !\")\n",
    "    \n",
    "    # Afficher un aper√ßu\n",
    "    print(\"\\nAper√ßu des cas suspects :\")\n",
    "    print(df_suspects[['nom', 'distance_domicile_km', 'score_risque', 'Dur√©e_minutes']].head(10))\n",
    "    \n",
    "    # Sauvegarder\n",
    "    chemin_sortie = '/Users/bourtguize/Desktop/fraudes_detectees.csv'\n",
    "    df_suspects.to_csv(chemin_sortie, index=False, sep=';', encoding='utf-8')\n",
    "    print(f\"\\n‚úì Fichier sauvegard√© sur le Bureau : fraudes_detectees.csv\")\n",
    "else:\n",
    "    print(\"\\nAucune fraude d√©tect√©e avec les crit√®res actuels\")\n",
    "    print(f\"Seuil de distance utilis√© : {seuil_distance} km\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "bed1b9c8-da41-4289-a491-3f37e01298b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Valeurs uniques dans 'activite' ===\n",
      "activite\n",
      "AA    17595\n",
      "RD    16631\n",
      "AR     3134\n",
      "AO       51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Valeurs uniques dans 'Description' ===\n",
      "Description\n",
      "Travail     17595\n",
      "Conduite    16631\n",
      "Repos        3134\n",
      "Dispo          51\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Voir les valeurs dans 'activite' et 'Description'\n",
    "print(\"=== Valeurs uniques dans 'activite' ===\")\n",
    "print(df_positions['activite'].value_counts())\n",
    "print()\n",
    "print(\"=== Valeurs uniques dans 'Description' ===\")\n",
    "print(df_positions['Description'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "b1155991-c2d0-40a7-9bbf-4d06ca2c348f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== R√âSULTAT DE LA FUSION ===\n",
      "Lignes apr√®s fusion : 37261\n",
      "\n",
      "=== EXEMPLES DE NOMS dans df_positions ===\n",
      "['ODIN' 'PRUDHOMME' 'RICHET' 'LAGRAOUI' 'POIRIER-DIT-CAULIER' 'ABERT'\n",
      " 'BIARGE' 'BENOIT' 'BOISSIERE' 'MARTY']\n",
      "\n",
      "=== EXEMPLES DE NOMS dans df_domiciles ===\n",
      "['BENOIT' 'LE GAGNE' 'TAILLASSON' 'BUMENN' 'FERREIRA NETO' 'PRUDHOMME'\n",
      " 'CARVALHO PINTO' 'LANSARD' 'GREITER' 'MALCHEAUX']\n",
      "\n",
      "=== Valeurs dans 'Description' apr√®s fusion ===\n",
      "Description\n",
      "Travail     17534\n",
      "Conduite    16574\n",
      "Repos        3098\n",
      "Dispo          55\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Lignes avec 'Travail' : 17534\n",
      "\n",
      "=== EXEMPLE DE DONN√âES ===\n",
      "    nom  latitude_position  longitude_position  latitude_domicile  \\\n",
      "0  ODIN            43.6516              4.0003            43.6889   \n",
      "2  ODIN            43.7402              4.2218            43.6889   \n",
      "4  ODIN            43.7405              4.2218            43.6889   \n",
      "6  ODIN            43.7363              4.2335            43.6889   \n",
      "8  ODIN            43.6581              3.9988            43.6889   \n",
      "\n",
      "   longitude_domicile Description  \n",
      "0              1.4706     Travail  \n",
      "2              1.4706     Travail  \n",
      "4              1.4706     Travail  \n",
      "6              1.4706     Travail  \n",
      "8              1.4706     Travail  \n"
     ]
    }
   ],
   "source": [
    "# Fusion manuelle pour v√©rifier\n",
    "df_merged_test = pd.merge(df_positions, df_domiciles, on='nom', how='inner')\n",
    "\n",
    "print(f\"=== R√âSULTAT DE LA FUSION ===\")\n",
    "print(f\"Lignes apr√®s fusion : {len(df_merged_test)}\")\n",
    "print()\n",
    "\n",
    "# V√©rifier les noms dans les deux DataFrames\n",
    "print(\"=== EXEMPLES DE NOMS dans df_positions ===\")\n",
    "print(df_positions['nom'].unique()[:10])\n",
    "print()\n",
    "print(\"=== EXEMPLES DE NOMS dans df_domiciles ===\")\n",
    "print(df_domiciles['nom'].unique()[:10])\n",
    "print()\n",
    "\n",
    "# V√©rifier la colonne Description apr√®s fusion\n",
    "if len(df_merged_test) > 0:\n",
    "    print(\"=== Valeurs dans 'Description' apr√®s fusion ===\")\n",
    "    print(df_merged_test['Description'].value_counts())\n",
    "    print()\n",
    "    \n",
    "    # Filtrer sur Travail\n",
    "    df_travail = df_merged_test[df_merged_test['Description'].str.lower().str.contains('travail', na=False)]\n",
    "    print(f\"Lignes avec 'Travail' : {len(df_travail)}\")\n",
    "    \n",
    "    if len(df_travail) > 0:\n",
    "        print(\"\\n=== EXEMPLE DE DONN√âES ===\")\n",
    "        print(df_travail[['nom', 'latitude_position', 'longitude_position', 'latitude_domicile', 'longitude_domicile', 'Description']].head())\n",
    "else:\n",
    "    print(\"‚ö† AUCUNE CORRESPONDANCE lors de la fusion !\")\n",
    "    print(\"Les noms ne correspondent pas entre les deux fichiers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "914b44f1-0cee-4a43-b7dd-15780c232083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== V√âRIFICATION APR√àS CORRECTION ===\n",
      "Exemples de noms dans df_positions :\n",
      "['ODIN' 'PRUDHOMME' 'RICHET' 'LAGRAOUI' 'POIRIER-DIT-CAULIER' 'ABERT'\n",
      " 'BIARGE' 'BENOIT' 'BOISSIERE' 'MARTY']\n",
      "\n",
      "Exemples de noms dans df_domiciles :\n",
      "['BENOIT' 'LE GAGNE' 'TAILLASSON' 'BUMENN' 'FERREIRA NETO' 'PRUDHOMME'\n",
      " 'CARVALHO PINTO' 'LANSARD' 'GREITER' 'MALCHEAUX']\n"
     ]
    }
   ],
   "source": [
    "# Extraire le dernier mot du nom (nom de famille) dans df_positions\n",
    "df_positions['nom'] = df_positions['nom'].str.strip().str.split(' ').str[-1].str.upper()\n",
    "\n",
    "print(\"=== V√âRIFICATION APR√àS CORRECTION ===\")\n",
    "print(\"Exemples de noms dans df_positions :\")\n",
    "print(df_positions['nom'].unique()[:10])\n",
    "print()\n",
    "print(\"Exemples de noms dans df_domiciles :\")\n",
    "print(df_domiciles['nom'].unique()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "3fce0159-dee0-4b73-b599-24da36feff08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== D√âTECTION DES FRAUDES ===\n",
      "Colonnes dans df_merged apr√®s fusion:\n",
      "['Date et heure de d√©but', 'Position', 'latitude_position', 'longitude_position', 'Date et heure de fin', 'V√©hicule', 'nom', 'activite', 'Description', 'Dur√©e', 'Pr√©nom', \"Date d'embauche\", 'Date de naissance', 'Carte N¬∞', 'Adresse 1', 'code_postal', 'commune', 'latitude_domicile', 'longitude_domicile']\n",
      "\n",
      "Aucun chauffeur en activit√© de travail trouv√©\n",
      "\n",
      "Aucune fraude d√©tect√©e\n"
     ]
    }
   ],
   "source": [
    "# Lancer la d√©tection\n",
    "print(\"\\n=== D√âTECTION DES FRAUDES ===\")\n",
    "df_suspects = detecter_fraudes(df_domiciles, df_positions, seuil_distance)\n",
    "\n",
    "if df_suspects is not None and len(df_suspects) > 0:\n",
    "    print(f\"\\n‚úì {len(df_suspects)} cas suspects d√©tect√©s !\")\n",
    "    print(\"\\nAper√ßu des cas suspects :\")\n",
    "    print(df_suspects[['nom', 'distance_domicile_km', 'score_risque']].head(10))\n",
    "    \n",
    "    # Sauvegarder\n",
    "    chemin_sortie = '/Users/bourtguize/Desktop/fraudes_detectees.csv'\n",
    "    df_suspects.to_csv(chemin_sortie, index=False, sep=';', encoding='utf-8')\n",
    "    print(f\"\\n‚úì Fichier sauvegard√© sur le Bureau : fraudes_detectees.csv\")\n",
    "else:\n",
    "    print(\"\\nAucune fraude d√©tect√©e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d045e5-d88e-428c-ade2-924a2fcfb504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35a1c1b-8946-49bb-8005-860a7fbfd6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80513c6-e192-49a0-9956-129a86df1e10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47773d36-303f-426b-b6ff-6162a611c9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
